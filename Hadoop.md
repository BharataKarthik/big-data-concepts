# Apache Hadoop

## Overview
Apache Hadoop is a framework that allows for distributed processing of large datasets across clusters of computers.

## Key Components
- **HDFS (Hadoop Distributed File System)**: A distributed file system that stores data across multiple nodes.
- **MapReduce**: A programming model for processing large datasets with parallel, distributed algorithms.
- **YARN (Yet Another Resource Negotiator)**: Manages cluster resources and job scheduling.
- **HBase**: A NoSQL database that runs on top of HDFS and supports real-time data access.

## Use Cases
- Batch processing of large datasets.
- Data warehousing solutions.
- Log and event data analysis.

---

